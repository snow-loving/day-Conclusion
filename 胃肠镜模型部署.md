# 1 环境部署

```
ubuntu20.04
gpu：2080ti
显卡驱动：470
gcc/g++ 9
cuda 11.1
cudnn 8.1.1 cudnn-11.2-linux-x64-v8.1.1.33.tar
tensorrt 7.2. (要求cuda11.1 cudnn8.1)
deepstream 5.1
opencv3.4.7
Anaconda
python3.6以及依赖环境
```
## 1.1 安装ubuntu
- 系统安装分区方式


```
boot 1G efi
swap 16G (根据内存可调) swap area
/ 剩下所有 选择EX4（具体名称忘记了，选项在最上边的xxx4）
```
## 1.2 安装显卡驱动

系统自带 Software & Updates，源选择清华源（下载速度比阿里源快），然后一定要reload，显卡驱动选择470（当前系统和2080ti显卡型号下自动推荐的），最后重启。

## 1.3 安装gcc g++
ubuntu20.04⾃带的gcc/g++版本都是9，如需要安装其他版本，如下：

```
sudo apt update
sudo apt-get update # 可选择性操作
sudo apt install gcc-7 g++-7
sudo ln -sf /usr/bin/gcc-7 /usr/bin/gcc
sudo ln -sf /usr/bin/gcc-7 /usr/bin/g++
```
## 1.4 安装cuda cudnn
安装包位置

```
/home/tianru/liu/00_CODE_RW/0613_alg_work/work_envs
```
安装命令：

```
sudo chmod a+x cuda_11.1.1_455.32.00_linux.run
sudo ./cuda_11.1.1_455.32.00_linux.run # 安装时候将驱动选项按回车键取消，其它正常安装就⾏
tar -xvf cudnn-11.2-linux-x64-v8.1.1.33.tar
cd cuda
sudo cp include/cudnn* /usr/local/cuda-11.1/include/
sudo cp cp lib64/libcudnn* /usr/local/cuda-11.1/lib64/
sudo chmod a+r /usr/local/cuda-11.1/include/cudnn*
sudo chmod a+r /usr/local/cuda-11.1/lib64/libcudnn*
```
更改环境变量 ~/.bashrc

```
#CUDA
export PATH=/usr/local/cuda-11.1/bin:$PATH
export LD_LIBRARY_PATH=/usr/local/cuda-11.1/lib64:$LD_LIBRARY_PATH
```
更改后```source ~/.bashrc```或重新打开终端，但凡涉及到修改环境变量，修改后都要执行此操作。
## 1.5 安装TensorRT
解压到固定位置，添加环境变量即可

```
cd /home/tianru/liu/00_CODE_RW/0613_alg_work/work_envs/
tar -xvf TensorRT-7.2.3.4.Ubuntu-18.04.x86_64-gnu.cuda-11.1.cudnn8.1.tar -C /home/tianru/
# TensorRT
export LD_LIBRARY_PATH=/home/tianru/TensorRT-7.2.3.4/targets/x86_64-linux-gnu/lib:$LD_LIBRARY_PATH
```

## 1.6 安装deepstream
- 安装依赖库

```
sudo apt-get install \
libssl1.0.0 \
libgstreamer1.0-0 \
gstreamer1.0-tools \
gstreamer1.0-plugins-good \
gstreamer1.0-plugins-bad \
gstreamer1.0-plugins-ugly \
gstreamer1.0-libav \
libgstrtspserver-1.0-0 \
libjansson4 \
libjson-glib-1.0-0 \
libgstrtspserver-1.0-dev

# 可能出现问题 1: 依赖安装问题：E: 软件包 libssl1.0.0 没有可安装候选
解决⽅法：
sudo gedit /etc/apt/sources.list
在末尾添加
deb http://security.ubuntu.com/ubuntu bionic-security main
```
也可按照```/home/tianru/liu/00_CODE_RW/0613_alg_work/work_envs/DeepStream_Install_Guide```安装
- 安装deepstream

```
sudo tar -xvf deepstream_sdk_v5.1.0_x86_64.tbz2 -C /
cd /opt/nvidia/deepstream/deepstream-5.1/
sudo ./install.sh
```
- 测试


```
cd /opt/nvidia/deepstream/deepstream-5.1/samples/configs/deepstream-app/
deepstream-app -c source30_1080p_dec_infer-resnet_tiled_display_int8.txt # 能正常运⾏说明cuda tensorrt deepstream 配置都没为题
```
## 1.7 编译安装opencv3.4.7
路径：```/home/tianru/liu/00_CODE_RW/0613_alg_work/work_envs/opencv-3.4.7```
压缩包路径：```/home/tianru/liu/00_CODE_RW/0613_alg_work/work_envs/opencv-3.4.7.zip```

```
sudo apt-get install unzip
unzip opencv-3.4.7.zip
cd opencv-3.4.7
mkdir build
cd build
cmake .. # 可能需要安装cmake，使用sudo apt-get install cmake
make -j8
make install
```
## 1.8 配置python环境
- 安装anaconda
```
# 下载linux版anaconda

bash Anaconda-xxxx.sh

# 如果没有自动添加环境变量，则手动添加
# conda
export PATH=/home/tianru/anaconda3/bin:$PATH
```
- 创建虚拟环境
```
conda create -n torch python=3.6
```
- 切换清华源
```
# 升级pip
python -m pip install -i https://pypi.tuna.tsinghua.edu.cn/simple --upgrade pip
# 配置清华园源
pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple
```
- 激活torch环境
```
source activate pytorch
```
- 安装pytorch和其他依赖
```
# 如果torch环境python是3.6以上的，此处安装pytorch版本可能会不一样
pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html
pip install opencv-python albumentations tensorboardX thop graphviz onnx
```

# 2 模型训练
当前已经⽐较完善的算法包括：上消化冲洗、早癌、38解剖位置三个识别模型，后期需要做的其它模型算法可以参考类似的⽅式完成，主要是数据处理、标注规则的改变。
## 2.1 数据预处理/增广

⽬前针对冲洗、早癌、38解剖位置模型算法，在标注数据处理完成后，数据参与训练之前，我会对数据做：（0）平滑mask区域（仅对早癌数据）--->（1）数据划分 --->（2）数据增⼴
- 平滑mask区域：仅仅对于早癌/息⾁腺瘤带区域标注的数据，将⼿动标注的早癌区域平滑。参考代码：
```
/home/tianru/liu/CODE/01_tianru1st/01_pytorch_train/data_preprocess/_01_mask_smooth.py
```
- 数据划分：参考代码
```
/home/tianru/liu/CODE/01_tianru1st/01_pytorch_train/data_preprocess/_03_split_1_clusify_train_test.py
```
- 数据增广：该步骤的⽬的是使⽤算法增⼴算法增⼴某些图像⽐较少的类别，使得类别间图像数量差异变⼩。参考代码
```
/home/tianru/liu/CODE/01_tianru1st/01_pytorch_train/data_preprocess/_05_38positions_data_aug_multi_threads.py
```
目前使用的增广方式为
```
def spatial_level_aug() -> Compose:
    return Compose([
        # HorizontalFlip(p=0.5),
        # VerticalFlip(p=0.5),
        IAAPerspective(p=0.5),
        # IAAPiecewiseAffine(p=0.5),
        IAAPiecewiseAffine(p=0.3, nb_rows=2, nb_cols=2),
])
def pixel_level_aug() -> Compose:
    return Compose([
        IAAAdditiveGaussianNoise(p=0.5),
        RandomBrightnessContrast(p=0.5),
        ISONoise(p=0.5),
        RandomGamma(p=0.5),
])
```
## 2.2数据和模型
目前数据的路径为：
```
/home/tianru/.tianru/liu/Dataset/
```

- 冲洗数据
目前冲洗数据标签为 “冲洗” 和 “未冲洗” 两类。
结肠镜冲洗模型：上⾯两点为胃镜部分，结肠镜冲洗模型数据标注⼯作还没开展。初步计划结肠镜冲洗模型数据来源为视频标注，冲洗部分开展流程为：
```
和赵医⽣商讨确定结肠镜冲洗标注规范、统⼀规范（⽬前所有的标注⼈员都没有标注过冲洗，还需要培训和统⼀标注规则--->视频中标注清洁图和脏图
--->视频解析为图像后，标注⼈员对标注图像初步筛查 --->⽤筛查后的图像进⾏验证集划分和相应的预处理和增⼴后，初步训练模型建议使⽤genet、efficientnet-b0/b1 
--->根据训练精度/验证集合/独⽴测试集的效果来确定是否需要对训练数据进⼀步筛选--->模型部署--->视频测试验证
```

- 早癌数据
分割任务，同时设有三个类别
- 38位置数据
38位置已有标签，剩下结肠镜11位置模型:该部分数据标注⼯作还在进⾏中，开发流程和胃镜部分类似。

## 2.3 模型训练
已有的模型：
```
efficientNet、GEnet、FPN、DeeplabV3+
```
目前efficientNet效果最优。代码路径：
```
/home/tianru/liu/CODE/01_tianru1st/01_pytorch_train/
```
代码目录结构：
```
├── 01_cancer_model_train.py
├── 01_deeplabv3_v2_model_train.py # 使⽤deeplabV3训练早癌模型
├── 03_position_center_model_train.py # 位置模型训练
├── 03_z1_calculate_cls_centers.py
├── 04_classify_model_train.py # 分类模型（冲洗/染⾊模型训练）
├── data_preprocess # 标注好的图像数据在训练前，需要做⼀些图像处理，提升训练精度和效率
│   ├── _01_mask_smooth.py # 对早癌标注数据mask图像⽬标区域平滑操作
│   ├── _02_gen_black_masks.py # 对正常（⽆早癌）图像⽣成全⿊mask图像
│   ├── _03_split_1_clusify_train_test.py # 随机分分类模型的训练集、验证集
│   ├── _03_split_train_test.py # 随机分早癌模型的训练集、验证集
│   ├── _04_zaug_2_seg_data_multi_threads_3cancer_cls.py # 早癌数据做数据增⼴和样本均衡
│   ├── _05_38positions_data_aug_multi_threads.py # 对位置分类数据做数据增⼴和样本均衡，增⼴⽅式做了修改，有的增⼴⽅式不能⽤到位置中
│   ├── _05_aug_multi_classify_data_multi_threads.py # 对分类数据做数据增⼴和样本均衡
│   ├── 38位置数据增广不能使用增广.md
│   ├── 38位置数据增广不能使用增广.xlsx # 38个位置的数据有的增⼴⽅式不能使⽤，具体参考这个⽂档
│   └── test.py
├── ranew
│   ├── data # pytorch数据读取部分代码
│   │   ├── cancer_dataloader.py
│   │   ├── cancer_dataset.py
│   │   ├── classify_dataloader.py
│   │   ├── classify_dataset.py
│   │   ├── constants.py
│   │   └── transforms.py
│   ├── loss
│   │   ├── center_loss.py # 对于位置分类模型定义的中⼼loss
│   │   ├── cross_entropy.py
│   │   ├── focal_loss.py
│   │   ├── seg_functions.py
│   │   ├── seg_losses.py
│   │   └── seg_metrics.py
│   ├── model
│   │   ├── build_model
│   │   │   ├── build_cancer_model.py
│   │   │   ├── build_classify_model.py
│   │   │   ├── build_deeplabv3.py
│   │   │   ├── build_deeplabv3_v2.py
│   │   │   ├── build_siammask_model.py
│   │   │   ├── build_track_model.py
│   │   │   ├── model_opt_lr.py
│   │   │   ├── model_resume.py
│   │   │   └── model_summary.py
│   │   ├── classify # 分类模型
│   │   │   ├── efficientnet_pretrained
│   │   │   ├── efficientnet.py
│   │   │   ├── efficientnet_structure.py
│   │   │   ├── GENet
│   │   │   ├── model_summary.txt
│   │   │   └── resnet.py
│   │   ├── feature_layer
│   │   │   ├── efficientnet_b0.txt
│   │   │   ├── genet_large.txt
│   │   │   ├── resnet50.txt
│   │   │   └── skips_feature.py
│   │   ├── general_layer
│   │   │   ├── adaptive_avgmax_pool.py
│   │   │   ├── conv2d_helpers.py
│   │   └── segment # 分割模型
│   │       ├── deeplabv3plus
│   │       ├── deeplabv3plus_v2
│   │       ├── FPN.py
│   ├── test
│   │   ├── cal_metrics.py
│   ├── train # 模型训练代码
│   │   ├── cancer_train.py
│   │   ├── classify_train.py
│   │   ├── position_center_train.py
│   └── utils
│       ├── average_metar.py
│       ├── log_helper.py
│       ├── main_helper.py
│       ├── print_model.py
├── requirment.txt
├── test.py
├── train_outputs # 训练生成文件
├── train_queue_2022.py # 多个模型训练脚本
├── train_queue.py
└── train_weights # 模型预训练权重
```
训练代码均设置了warm_up，所以训练时不要将epochs设为1。

# 3 模型序列化
模型训练后，需要将torch训练的模型转化为onnx模型，在将onnx模型转化为tensorrt的序列化模型才用作后面的推理。
## 3.1 硬件环境
当前开发环境使⽤的是英伟达显卡作为推理硬件，项⽬中使⽤的显卡主要有3种：
- 1660s：最初使⽤的硬件，该显卡不⽀持半精度浮点运算，TensorRT序列化的模型只能以fp32的形式做推理。样机上同时运⾏冲洗+位置+早癌模型都不能实时。
- 2060: 和1660s最主要的区别就是该卡⽀持半精度浮点运算，TensorRT序列化的模型为fp16的形式，减少运算量，样机上同时运⾏冲洗+位置+早癌模型能实时，这也是⽬前的⽅案。
- 2080ti（当前使用）：服务器模型训练的显卡，在2080ti上序列化的模型可以在20系或16系列显卡上直接运⾏。
- 3090: 服务器模型训练的显卡，该显卡上序列化的模型不能在2060和1660s上运⾏。且该显卡只能使⽤cuda11以上的版本。

## 3.2 序列化流程
代码路径：
```
/home/tianru/liu/CODE/01_tianru1st/02_deepstream_tianru1st/01_pygen_onnx_engine_model/
```
- 位置模型计算中⼼点和距离阈值：（目前仅在位置识别任务中使用） 
```
00_calculate_cls_centers.py
# 参数设置：
num_classes = 42
# 0-37:38个解剖位置 放⼤：38 模糊：39 体外：40 近镜头：41
feature_file ="/home/tianru/liu/CODE/01_tianru1st/01_pytorch_train/train_outputs/20220624-114124_pose42/train_center_log/epoch_1.npy"
```
- 模型序列化流程： pytorch模型加载-->重新定义每个模型的输出接⼝-->转onnx模型-->onnx模型简化-->tensorrt模型序列化

根据自己的路径进行修改
```
model_flush = '/home/tianru/liu/CODE/01_tianru1st/01_pytorch_train/train_outputs/xxx/checkpoint_xxx.pth'
model_cencer = '/home/tianru/liu/CODE/01_tianru1st/01_pytorch_train/train_outputs/20220624-133608_cancer/checkpoint_e1.pth'
model_position = '/home/tianru/liu/CODE/01_tianru1st/01_pytorch_train/train_outputs/20220624-114124_pose42/checkpoint_e1.pth'
center_file = '/home/tianru/liu/CODE/01_tianru1st/01_pytorch_train/train_outputs/20220624-114124_pose42/train_center_log/epoch_1.npy_cls_centers.txt'
num_center = 42
```
重新定义每个模型的输出接⼝：主要是确定tensorrt模型推理后模型输出的数据类容和格式，这个不⼀定和训练时⼀样，具体的定义都在 00_calculate_cls_centers.py
onnx模型简化：使⽤的是onnxsim库，有的模型不简化，在转tensorrt过程中会报错
## 3.3 可能遇到的问题
- ```ERROR: No matching distribution found for onnxsim```
缺少相应的库
```
pip install onnx-simplifier
```
- ```ModuleNotFoundError: No module named ‘tensorrt‘ 或者 tensorrt ImportError: No module named ‘tensorrt‘```

```
pip install nvidia-pyindex
pip install nvidia-tensorrt
pip install pycuda
```

- ```ModuleNotFoundError: No module named 'torch.utils.serialization 或者 AttributeError: ‘tensorrt.tensorrt.Builder‘ object has no attribute ‘max_workspace_size'```
网上资料说是版本过新导致，回退到tensorrt-7.x 版本解决。

- 第二点安装tensorrt是通过网络解决的办法，本项目使用的代码和网上的demo不一样，因此会出现报错
```
[TensorRT] WARNING: onnx2trt_utils.cpp:220: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.
[TensorRT] WARNING: onnx2trt_utils.cpp:246: One or more weights outside the range of INT32 was clamped
[TensorRT] ERROR: Network must have at least one output
[TensorRT] ERROR: Network validation failed.
Traceback (most recent call last):
  File "02_202203_pytorch_model2trt_deepstream.py", line 277, in <module>
    ONNX2TRT(onnx_file_path='models/p_compose_sim.onnx', engine_file_path='models/p_compose_fp32.engine', mode='fp32', batch_size=32)
  File "/home/tianru/liu/CODE/01_tianru1st/02_deepstream_tianru1st/01_pygen_onnx_engine_model/trt_engine_utils/trt_convertor.py", line 53, in ONNX2TRT
    f.write(engine.serialize())
AttributeError: 'NoneType' object has no attribute 'serialize'
double free or corruption (!prev)
Aborted (core dumped)
```
因此解决办法有所不同，按照上面的方法，pip安装依赖是行不通的，因此只能uninstall之前安装的tensorrt，转而使用pip手动安装。tensorrt的安装包路径
```
/home/tianru/liu/00_CODE_RW/0613_alg_work/work_envs/TensorRT-7.2.3.4.Ubuntu-18.04.x86_64-gnu.cuda-11.1.cudnn8.1/TensorRT-7.2.3.4/
cd TensorRT-7.2.3.4/python/ #上述路径
source activate torch 
pip install tensorrt-7.2.3.4-cp36-none-linux_x86_64.whl #根据torch环境python的版本选择whl文件
cd ../graphsurgeon/
pip install graphsurgeon-0.4.5-py2.py3-none-any.whl
```

- 上一步完成后如果在pycharm里直接调试代码，可能会出现```ImportError: libnvinfer.so.7: cannot open shared object file: No such file or directory```，这个是pycharm自身编译环境的问题，不影响在终端运行程序。若要在编辑器中调试代码，参考```https://blog.csdn.net/xulingjie_online/article/details/113943508```解决该问题。

# 4 Deepstream编译
## 4.1 编译步骤
编译步骤与opencv编译类似,第一次编译生成模型推理动态链接库的cmake文件，第二次编译测试模型推理动态链接库的cmake文件。在编译前通过软链接到不同的cmake文件完成不同的功能。

注意：
1. 需编译两次，有先后次序
2. 首次编译需清空```build```文件夹 

```
cd /home/tianru/liu/CODE/01_tianru1st/02_deepstream_tianru1st/02_deepstream-videocard-to-qtlib_30xx/build
ln -sf CMakeLists_lib.txt CMakeLists.txt
cmake ..
make 
ln -sf CMakeLists_exe.txt CMakeLists.txt
cmake ..
make
```
编译完成后生成libnvgstqt.so动态链接库和可执行文件deepstream_test1_app，生成文件在```build```目录下，然后将库文件拷贝至```/home/tianru/.tianru/libs/lib_depend/```，可执行文件拷贝至```/home/tianru/.tianru/libs/```供后续操作使用。下面是编译后的```build```目录结构。


```
├── build
│   ├── CMakeCache.txt
│   ├── CMakeFiles/
│   ├── cmake_install.cmake
│   ├── deepstream_test1_app # 可执行文件
│   ├── libnvgstqt.so # 动态链接库
│   └── Makefile

```
## 4.2 deepstream主要插件使用及连接图
- 创建链接视频流source_bin
对应代码src/GstQt.cpp：

```
NvDsSrcParentBin multi_src_bin;
if (!create_multi_source_bin (1, &config_source, &multi_src_bin))
g_printerr("Failed to create multi_source_bin. \n");
gst_bin_add (GST_BIN (pipeline), multi_src_bin.bin);
config_streammux.pipeline_width = config_source.width;
config_streammux.pipeline_height = config_source.height;
set_streammux_properties (&config_streammux, multi_src_bin.streammux); // set multi_src_bin stream mux para
```
- 创建链接模型推理部分插件primary_gie_bin
```
NvDsPrimaryGieBin primary_gie_bin;
if (!create_primary_gie_bin (&config_gie, &primary_gie_bin)) # 这⾥⾯分别创建冲洗、位置、早癌模型推理primary_gie_bin
g_printerr("Failed to create primary_gie_bin. \n");
gst_bin_add (GST_BIN (pipeline), primary_gie_bin.bin);
```
## 4.3 模型文件配置
代码路径：```/home/tianru/liu/CODE/01_tianru1st/02_deepstream_tianru1st/02_deepstream-videocard-to-qtlib_30xx```

- （1）编译nvdsinfer_customparser
（之前的文档内容，目前还存在一些问题）
需要配置：nvdsinfer_customparser

nvdsinfer_customparser有部分代码修改，主要是cancer模型的预测结果解析，参考： ```02_deepstream-videocard-to-qtlib_30xx/nvdsinfer_customparser```，将该⽬录下的⽂件拷贝到```/home/tianru/deepstream-5.1/sources/libs/nvdsinfer_customparser/```，就只需在该⽬录下make，会⽣成：libnvds_infercustomparser.so，该⽂件会在：tr_cancer_config.txt中调⽤
```
parse-bbox-instance-mask-func-name=NvDsInferParseCustomCancer
custom-lib-path=/home/tianru/deepstream-5.1/sources/libs/nvdsinfer_customparser/libnvds_infercustomparser.so
```
- （2）配置config文件

config文件路径：```/home/tianru/.tianru/```，此处的```.engine```文件由模型序列化后生成，需拷贝至此处。fp16是半精度浮点数，使用2字节编码存储，fp32是单精度浮点数，使用4字节编码存储，不同方式存在计算速度的差异。
```
目录结构
tianru@tianru:~$ tree .tianru/
.tianru/
├── configs
│ ├── c_compose_fp16.engine # c_xx.engine为早癌模型文件
│ ├── c_compose_fp32.engine 
│ ├── f_compose_fp16.engine # f_xx.engine为冲洗模型文件
│ ├── f_compose_fp32.engine
│ ├── p_compose_fp16.engine # p_xx.engine为位置模型文件
│ ├── p_compose_fp32.engine
│ ├── labels_cancer.txt # label_xx.txt为不同任务的标签文件
│ ├── labels_flush.txt
│ ├── labels_position12.txt
│ ├── labels_position.txt
│ ├── tr_cancer_config.txt # tr_xx_config.txt为不同推理任务的配置文件
│ ├── tr_flush_config.txt
│ └── tr_position_config.txt
└── libs/ # 存放相关的动态链接库与编译生成的可执行文件，具体内容在部署环节讲解
└── video_info
```
编译时根据不同的任务对config文件进行修改，个别参数需要修改，大部分都不用动，以下是分类的，分割任务有一些不同，按情况修改即可。

```
[property]
gpu-id=0 # 根据gpu的数量确定该参数
gie-unique-id=1
model-engine-file=f_compose_fp16.engine # 选取目标任务的engine文件
labelfile-path=labels_flush.txt # 对应的标签文件

# 0=FP32 and 1=INT8 mode 2=FP16
network-mode=0

output-blob-names=f_out
#custom-lib-path=/home/tianru/packages/deepstream_sdk_v5.0.1_x86_64/opt/nvidia/deepstream/deepstream/sources/libs/nvdsinfer_customparser/libnvds_infercustomparser.so
#parse-classifier-func-name=NvDsInferClassiferParseCustomSoftmax
# 0=Detector, 1=Classifier, 2=Segmentation, 100=Other
network-type=1
force-implicit-batch-dim=1
batch-size=1
```

## 4.4 项目结构
项⽬路径：```/home/tianru/liu/CODE/01_tianru1st/02_deepstream_tianru1st/02_deepstream-videocard-to-qtlib_30xx```

```
├── 01_build_exe.cpp # 测试01_build_infer_pipeline_lib.c⽣成的模型推理动态链接库是否正常稳定,
运⾏的可执⾏main代码，通过CMakeLists.txt -> CMakeLists_exe.txt实现编译选项的切换
├── CMakeLists_exe.txt # 测试模型推理动态链接库的cmake⽂件
├── CMakeLists_lib.txt # ⽣成模型推理动态链接库cmake⽂件
├── CMakeLists.txt -> CMakeLists_exe.txt # 通过链接到上⾯两个不同的cmake⽂件完成不同的功能
├── common_includes # 这⾥⾯都是deepstream常⽤的头⽂件
│ ├── gstnvdsinfer.h
│ ├── gstnvdsmeta.h
│ ├── nvbufsurface.h
│ ├── nvdsinfer.h
│ ├── nvds_latency_meta.h
│ ├── nvdsmeta.h
│ └── nvll_osd_struct.h
├── config # 这是模型推理设置⽂件
│ ├── labels_cancer.txt
│ ├── labels_flush.txt
│ ├── labels_position12.txt
│ ├── labels_position38.txt
│ ├── tr_cancer_config.txt
│ ├── tr_flush_config.txt
│ └── tr_position_config.txt # 这是⾃定义⼏个重要的deepstream插件的congfig⽂件
├── config_includes
│ ├── config_gie.h
│ ├── config_osd.h
│ ├── config_sink.h
│ └── config_sources.h
├── dot_structure # ⽣成的deeptream结构图
│ ├── deepstream_tianru1st_v1.png
│ ├── deepstream_tianru1st_v2.png
│ └── deepstream_tianru1st_v3.png
├── includes
│ ├── deepstream_common.h
│ ├── deepstream_config.h
│ ├── deepstream_dewarper.h
│ ├── deepstream_gie.h
│ ├── deepstream_osd.h
│ ├── deepstream_primary_gie.h
│ ├── deepstream_sinks.h
│ ├── deepstream_sources.h
│ ├── GstQt.hpp # VIP：接⼝类实现类头⽂件
│ └── INvGstQt.hpp  # VIP： 接⼝类
├── nvdsinfer_customparser
│ ├── Makefile
│ ├── nvdsinfer_custombboxparser.cpp
│ └── nvdsinfer_customclassifierparser.cpp
├── README
└── src
├── deepstream_common.c
├── deepstream_osd_bin.c
├── deepstream_primary_gie_bin.c
├── deepstream_sink_bin.c
├── deepstream_source_bin.c
└── GstQt.cpp # 接⼝类实现类具体实现，功能这要就是在这⾥实现的
```
## 4.5 主要代码讲解
该项⽬的构建⽅式和之前仅仅使⽤TensorRT同样的⽅式。
- （1）```CMakeLists_lib.txt```

构建deepstream模型预测以及输出结果的动态链接库：```libnvgstqt.so```
```
INvGstQt.hpp # 这是动态链接库接⼝头⽂件，部署时需要copy到部署设备

GstQt.hpp/GstQt.cpp # deepstream关键类，看代码从该部分的构建函数开始： TRNvGst();
```
- （2）```CMakeLists_exe.txt```

测试动态链接库 ：```libnvgstqt.so```的调⽤，需要引⽤： 

```
target_link_libraries(deepstream_test1_app /home/tianru/liu/CODE/01_tianru1st/02_deepstream_tianru1st/02_deepstream-videocard-to-qtlib_30xx/build/libnvgstqt.so)
```
- （3）其他源码

deepstream主要的代码是在：GstQt.hpp/GstQt.cpp 的构建函数 TRNvGst();

```
Tr::TRNvGst::TRNvGst() {
    pThis = this;
    
    // parse video info
    get_video_crop_info("/home/tianru/.tianru/video_info", &config_source);
    
    g_setenv("GST_DEBUG_DUMP_DOT_DIR", "/home/tianru", TRUE);
    gst_init (NULL, NULL);
    
    /*
     * Create pipeline
     */
    GstElement *pipeline = NULL;
    pipeline = gst_pipeline_new ("pipeline");
    if (!pipeline) {
    g_printerr("Failed to create pipeline. \n");
    }
    
    // create source bin
    NvDsSrcParentBin multi_src_bin;
    if (!create_multi_source_bin (1, &config_source, &multi_src_bin))
    g_printerr("Failed to create multi_source_bin. \n");
    gst_bin_add (GST_BIN (pipeline), multi_src_bin.bin);
    config_streammux.pipeline_width = config_source.width;
    config_streammux.pipeline_height = config_source.height;
    set_streammux_properties (&config_streammux, multi_src_bin.streammux); // set multi_src_bin stream mux para
    
    // create primary gie
    NvDsPrimaryGieBin primary_gie_bin;
    if (!create_primary_gie_bin (&config_gie, &primary_gie_bin))
        g_printerr("Failed to create primary_gie_bin. \n");
    gst_bin_add (GST_BIN (pipeline), primary_gie_bin.bin);
   
    // link bins: 从后往前连接
    GstElement *last_elem;
    last_elem = primary_gie_bin.bin;
    NVGSTDS_LINK_ELEMENT (multi_src_bin.bin, last_elem);
    
    /*
     * create loop
     */
    GMainLoop *loop = NULL;
    loop = g_main_loop_new (NULL, FALSE);
    
    /*
     * create bus
     */
    GstBus *bus = NULL;
    bus = gst_pipeline_get_bus (GST_PIPELINE (pipeline));
    m_bus_watch_id = gst_bus_add_watch (bus, bus_call, loop);
    gst_object_unref (bus);
    
    // cancer
    GstPad *nvinfer_src_pad_cancer = NULL;
    nvinfer_src_pad_cancer = gst_element_get_static_pad(primary_gie_bin.primary_gie_cancer, "src");
    if (!nvinfer_src_pad_cancer)
        g_print ("Unable to get nvinfer src pad.\n");
    else
        if(config_osd.draw_mask){
            g_print("run nvinfer_src_pad_buffer_probe. \n");
            gst_pad_add_probe(nvinfer_src_pad_cancer, GST_PAD_PROBE_TYPE_BUFFER, nvinfer_src_pad_buffer_probe, NULL, NULL);
        }
        else{
            g_print("run nvinfer_src_pad_buffer_probe_return_mask. \n"); // run this
            gst_pad_add_probe (nvinfer_src_pad_cancer, GST_PAD_PROBE_TYPE_BUFFER, nvinfer_src_pad_buffer_probe_return_mask, NULL, NULL);
        }
    gst_object_unref (nvinfer_src_pad_cancer);
   
    // set get source appsink data's callback
    gst_app_sink_set_emit_signals((GstAppSink*)multi_src_bin.sub_bins->source_sink,
    true);
    gst_app_sink_set_drop((GstAppSink*)multi_src_bin.sub_bins->source_sink, true);
    gst_app_sink_set_max_buffers((GstAppSink*)multi_src_bin.sub_bins->source_sink, 1);
    GstAppSinkCallbacks callbacks = { nullptr, new_preroll, new_sample};
    gst_app_sink_set_callbacks(GST_APP_SINK(multi_src_bin.sub_bins->source_sink),
    &callbacks, nullptr, nullptr);
   
    // draw pipeline dot
    // GST_DEBUG_BIN_TO_DOT_FILE(GST_BIN (pipeline), GST_DEBUG_GRAPH_SHOW_ALL, "ds-app-null-file");
    
    /*
     * init class para
     */
    m_pipeline = pipeline;
    m_loop = loop;
}
```
然后载分部分阅读每个部分的：

```
├── includes
│ ├── deepstream_common.h
│ ├── deepstream_config.h
│ ├── deepstream_dewarper.h
│ ├── deepstream_gie.h
│ ├── deepstream_osd.h
│ ├── deepstream_primary_gie.h
│ ├── deepstream_sinks.h
│ ├── deepstream_sources.h
│ ├── GstQt.hpp
│ └── INvGstQt.hpp
└── src
├── deepstream_common.c
├── deepstream_osd_bin.c
├── deepstream_primary_gie_bin.c
├── deepstream_sink_bin.c
├── deepstream_source_bin.c
└── GstQt.cpp
```
## 4.6 变更模型编译代码修改
当有其他需求需要加入到部署任务中时，需在深度学习代码中训练出对应的模型，然后将模型转换成trt，再修改deepstream代码重新编译后部署。
目前可能需要修改的代码主要有：
```
config_gie.h
deepstream_gie.h
deepstream_primary_gie.h
InvGstQt.hpp
deepstream_primary_gie_bin.c
GstQt.cpp
01_build_exe.cpp
labels_xx.txt # 目标任务标签，和 /.tianru/configs/ 中的文件内容同步
tr_xx_config.txt # 目标任务配置文件，和 /.tianru/configs/ 中的文件内容同步
```
- ```config_gie.h```

```
定义配置文件路径
.config_file_path_flush = "/home/tianru/.tianru/configs/tr_flush_config.txt",
.config_file_path_position = "/home/tianru/.tianru/configs/tr_position_config.txt",
.config_file_path_cancer = "/home/tianru/.tianru/configs/tr_cancer_config.txt",
.config_file_path_hp3 = "/home/tianru/.tianru/configs/tr_hp3_config.txt",
```
- ```deepstream_gie.h```

```
gchar *config_file_path_flush;

guint unique_id_flush;
```
- ```deepstream_primary_gie.h```
```
GstElement *primary_gie_flush;

GstElement *fake_sink_flush;
```
- ```InvGstQt.hpp```

```
float flush_prob;
std::string flush_label;
```
- ```deepstream_primary_gie_bin.c```

```
bin->primary_gie_flush = gst_element_factory_make (NVDS_ELEM_PGIE, "primary_gie_flush");

bin->fake_sink_flush = gst_element_factory_make("fakesink", "fake_sink_flush");

if (!bin->primary_gie_flush) {
    NVGSTDS_ERR_MSG_V ("Failed to create primary_gie_flush");
    goto done;
  }

if (!bin->fake_sink_position || !bin->fake_sink_flush || !bin->fake_sink_hp3||!bin->primary_tee) {
    NVGSTDS_ERR_MSG_V ("Failed to create fake_sink");
    goto done;
}

g_object_set (G_OBJECT (bin->primary_gie_flush), "config-file-path", GET_FILE_PATH (config->config_file_path_flush), "process-mode", 1, NULL);
if (config->is_batch_size_set)
    g_object_set (G_OBJECT (bin->primary_gie_flush), "batch-size", config->batch_size, NULL);
if (config->is_interval_set)
    g_object_set (G_OBJECT (bin->primary_gie_flush), "interval", config->interval, NULL);
if (config->is_unique_id_set)
    g_object_set (G_OBJECT (bin->primary_gie_flush), "unique-id", config->unique_id_flush, NULL);
    
if (config->is_gpu_id_set)
    g_object_set (G_OBJECT (bin->primary_gie_flush), "gpu-id", config->gpu_id, NULL);
if (config->model_engine_file_path)
    g_object_set (G_OBJECT (bin->primary_gie_flush), "model-engine-file", GET_FILE_PATH (config->model_engine_file_path), NULL);
    
g_object_set (G_OBJECT (bin->fake_sink_flush), "async", FALSE, "sync", FALSE, "enable-last-sample", FALSE, NULL);

gst_bin_add_many (GST_BIN (bin->bin), bin->queue, bin->nvvidconv, bin->primary_gie_flush,
                      bin->primary_gie_position, bin->primary_gie_cancer, bin->primary_gie_hp3,
                      bin->fake_sink_position, bin->fake_sink_flush, bin->fake_sink_hp3, bin->primary_tee,
                      bin->fake_sink_cancer, caps_filter_sink, NULL);


NVGSTDS_LINK_ELEMENT(bin->primary_tee, bin->primary_gie_flush);
NVGSTDS_LINK_ELEMENT(bin->primary_gie_flush, bin->fake_sink_flush);
```
- ```GstQt.cpp```

```
switch (label_info->result_label[0]) {  # 另有一处函数修改的地方和这里一样，不再赘述
    case 'F':
        pThis->m_classifier_results.flush_prob = label_info->result_prob;
        pThis->m_classifier_results.flush_label =  label_info->result_label;
        break;
```
- ```01_build_exe.cpp```
```
g_print("outside callback: flush: %f  %s    position: %f  %s   cancer: %f  %s   hp3: %f  %s.\n",
    r.flush_prob, r.flush_label.c_str(), r.position_prob, r.position_label.c_str(),
    r.cancer_prob, r.cancer_label.c_str(), r.hp3_prob, r.hp3_label.c_str());
```



## 4.7 可能遇到的问题
- （1）```fatal error: gst/gst.h: No such file or directory```

make时报错，该显示错误代码为1696，原因是没有安装gstreamer，装上即可，刚开始发现anaconda里也安装了这个依赖库，索性把路径直接换成anaconda的路径，但又出现了一些权限问题，于是又在ubuntu上直接装了gstreamer。

```
sudo apt-get update

sudo apt-get install libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev \
libgstreamer-plugins-bad1.0-dev gstreamer1.0-plugins-base gstreamer1.0-plugins-good \
gstreamer1.0-plugins-bad gstreamer1.0-plugins-ugly gstreamer1.0-libav \
gstreamer1.0-doc gstreamer1.0-tools gstreamer1.0-x gstreamer1.0-alsa gstreamer1.0-gl 
CMakeLists.txt文件：
include_directories(
        common_includes
        includes
        config_includes
         /usr/include/gstreamer-1.0
#        /home/tianru/anaconda3/include/gstreamer-1.0
        /usr/include/glib-2.0
        ${SYS_USR_LIB}/glib-2.0/include
)
```
- (2)```No such file or directory```

这类问题大部分是由于路径写错导致的，注意以下几处代码：

```
config_gie.h文件:
.config_file_path_flush = "/home/tianru/.tianru/configs/tr_flush_config.txt",
.config_file_path_position = "/home/tianru/.tianru/configs/tr_position_config.txt",
.config_file_path_cancer = "/home/tianru/.tianru/configs/tr_cancer_config.txt",

CMakeLists.txt文件：
target_link_libraries(deepstream_test1_app /home/tianru/liu/CODE/01_tianru1st/02_deepstream_tianru1st/02_deepstream-videocard-to-qtlib_30xx/build/libnvgstqt.so)
```


# 5 部署
天如⼀号deepstream版本推理部分的样机部署还是⽐较简单的，最简单的⽅式就是像部署开发环境⼀样，将显卡驱动、CUDA、TensorRT、Deepstream都部署⼀遍，下⾯介绍简单的，只安装使⽤到的库⽂件的⽅式，使用视频采集卡模拟输入视频场景。

## 5.1 目录结构
在上一章节中编译生成```deepstream_test1_app 和 libnvgstqt.so```，将```deepstream_test1_app```拷贝到```/home/tianru/.tianru/libs/```,将```libnvgstqt.so```拷贝到```/home/tianru/.tianru/libs/lib_depend/```。

```
.tianru
├── libs
│ ├── deepstream_test1_app # 编译生成的可执行文件
│ ├── install_ds.sh 
│ ├── lib_cuda/ #相关依赖库
│ ├── lib_depend/
│ ├── lib_ds/
│ ├── lib_ds_gst_plugins/
│ ├── lib_trt/
│ ├── uninstall.sh
└── configs/
```

其中：
lib_depend: 使⽤copy_lib.sh deepstream_test_app,对deepstream_test_app依赖的路⽂件进⾏拷⻉；（总计22）
lib_cuda：使⽤下⾯第⼆点的⽅式确认的cuda必要⽂件库；(总计 13)
lib_ds_gst_plugins：deepstream-5.1/lib/gst-plugins 原本的库⽂件；（总计 22）
lib_trt: 使⽤下⾯第⼀点的⽅式确认的tensorrt必要库⽂件; （总计 5）
lib_ds: 使⽤下⾯第⼀点的⽅式确认deepstream-5.1/lib必要库⽂件。（总计 21）

## 5.2 部署步骤
环境路径：
```
/home/tianru/.tianru
/home/tianru/.tianru/video_info # 视频有效区域分割
/home/tianru/.tianru/configs # deepstream模型⽂件和相关配置⽂件
/home/tianru/.tianru/libs # 库⽂件
```
- （1）环境变量 ~/.bashrc


```
export LD_LIBRARY_PATH=/home/tianru/.tianru/libs/lib_depend:$LD_LIBRARY_PATH
export LD_LIBRARY_PATH=/home/tianru/.tianru/libs/lib_trt:$LD_LIBRARY_PATH
export LD_LIBRARY_PATH=/home/tianru/.tianru/libs/lib_ds:$LD_LIBRARY_PATH
```
完成次步骤需重新打开终端或
```
source ~/.bashrc
```
在进行后续步骤
- （2）/etc/ld.so.conf.d/cuda-tianru.conf (ldconfig 配置 lib_ds_gst_plugins 需要)

```
在文件中写入：
/home/tianru/.tianru/libs/lib_cuda
```

- （3）chmod -R 777 libs （这步很重要，copy过来的库⽂件很可能权限不够）
- （4）执⾏ install_ds.sh

```
#!/bin/bash
update-alternatives --install /usr/lib/x86_64-linux-gnu/gstreamer-1.0/deepstream deepstream-plugins /home/tianru/.tianru/libs/lib_ds_gst_plugins 51
ldconfig
rm -rf /home/*/.cache/gstreamer-1.0/
rm -rf /root/.cache/gstreamer-1.0/
```

- （5）执行 deepstream_test1_app
- （6）执行 uninstall.sh
```
注意：下⾯两⾏很重要，不然也⽆法部署成功，均写在安装卸载脚本中
rm -rf /home/*/.cache/gstreamer-1.0/
rm -rf /root/.cache/gstreamer-1.0/
```

## 5.3 可能遇到的问题
```
ERROR from element src_elem: Internal data stream error.
Error details: gstbasesrc.c(3072): gst_base_src_loop (): /GstPipeline:pipeline/GstBin:multi_src_bin/GstBin:src_sub_bin0/GstV4l2Src:src_elem:
streaming stopped, reason not-negotiated (-4)
Finish!
```
视频采集卡的插口不对，换个插口即可。
